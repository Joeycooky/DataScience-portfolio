{"cells":[{"metadata":{},"cell_type":"markdown","source":"# BMW Price prediction","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<img src=\"https://static.bangkokpost.com/media/content/20200305/c1_1872299.jpg\" alt=\"BMW logo\" width=\"800.33\" height=\"200\">","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"# Introduction\n\nDreaming of having a BMW? Here is your tools to help you select for best value BMW in the market.\n\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a class=\"anchor\" id=\"0.1\"></a>\n\n## Table of Contents\n\n1. [Import libraries](#1)\n1. [Download datasets](#2)\n1. [EDA](#3)\n1. [Preparing to modeling](#4)\n1. [Tuning models](#5)\n    -  [Linear Regression](#5.1)\n    -  [Support Vector Machines](#5.2)\n    -  [Linear SVR](#5.3)\n    -  [MLPRegressor](#5.4)\n    -  [Stochastic Gradient Descent](#5.5)\n    -  [Decision Tree Regressor](#5.6)\n    -  [Random Forest with GridSearchCV](#5.7)\n    -  [XGB](#5.8)\n    -  [LGBM](#5.9)\n    -  [GradientBoostingRegressor with HyperOpt](#5.10)\n    -  [RidgeRegressor](#5.11)\n    -  [BaggingRegressor](#5.12)\n    -  [ExtraTreesRegressor](#5.13)\n    -  [AdaBoost Regressor](#5.14)\n    -  [VotingRegressor](#5.15)\n1. [Models comparison](#6)\n1. [Prediction](#7)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 1.  Data import and cleaning","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Dataset explanation\n\nData is provided by 100,000 UK Used car dataset (https://www.kaggle.com/adityadesai13/used-car-dataset-ford-and-mercedes).For this notebook, we condiser only BMW car which has following features used for prediction of its price\n\n1. model : model of the cars (i.e. 5 Series, X3, etc.)\n2. year : year of 1st hand purchased\n3. transmission : mode of transmission (manual or automatic or semi-auto)\n4. mileage : total mileage of the car\n5. tax : road tax incured\n6. mpg : miles per gallon consumption\n7. engineSize : in units of litres","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/used-car-dataset-ford-and-mercedes/bmw.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dataset was properly collected. There are no missing value presented. So in data preprocessing step, we can skip imputation process.\n\nTo gain further insight, I decide to add new columns to calculate vehicle age from its year since it might be a useful predictor for predict car price","execution_count":null},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"#Age calculation (present year - year of purchased)\ndf['age'] = 2020 - df['year']\ndf = df.drop(columns = 'year')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"#Since there might be error in data gathered (There is petrol and diesel car that have engine size of 0)\ndf[df['engineSize'] == 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's drop instances which fuelType are Diesel or Petrol but have 0.0 engineSize out.\ndf = df.drop(df[(df['engineSize'] == 0) & (df['fuelType'].isin(['Diesel','Petrol']))].index)\ndf[df['engineSize'] == 0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Exploratory Data Analysis","execution_count":null},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"df['engineSize'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_col = df.select_dtypes(include = object).columns.tolist() + ['engineSize']\nnum_col = df.select_dtypes(exclude = object).columns.tolist()\nnum_col.remove('engineSize')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Univaraiate analysis","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#numerical data\nfig = plt.figure(figsize=(20,20))\nsns.set_style('darkgrid')\nfor index,col in enumerate(num_col):\n    plt.subplot(3,2,index+1)\n    sns.distplot(df[col])\nfig.tight_layout(pad=1.0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data observation #1","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Categorical feature\nfig = plt.figure(figsize=(20,20))\nsns.set_style('darkgrid')\nfor index,col in enumerate(cat_col):\n    plt.subplot(2,2,index+1)\n    if(index == 0):\n        plt.xticks(rotation=90)\n    sns.set(font_scale = 1.5)\n    sns.countplot(df[col], order = df[col].value_counts().index)\n\n    \nfig.tight_layout(pad=1.0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data observation #2","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Bivariate Analysis","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#\nfig = plt.figure(figsize=(10,10))\nsns.set(font_scale = 1.0)\nsns.relplot(x=\"mileage\", y=\"price\", hue=\"transmission\", size=\"age\",\n            sizes = (20,200), alpha=.5, palette=\"muted\", aspect = 1.5 ,data=df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.heatmap(df.corr(), annot=True, cmap='RdBu')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finding 1","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(style=\"ticks\")\n\n# Initialize the figure\nf, ax = plt.subplots(figsize=(8, 10))\n\n# Plot the orbital period with horizontal boxes\nsns.boxplot(x=\"price\", y=\"model\", data=df,\n            whis=[0, 100], palette=\"vlag\",\n           order = df.groupby('model').median().sort_values(by = 'price').index)\n\n# Add in points to show each observation\n# sns.swarmplot(x=\"distance\", y=\"method\", data=planets,\n#               size=2, color=\".3\", linewidth=0)\n\n# Tweak the visual presentation\nax.xaxis.grid(True)\nax.set(ylabel=\"Model\")\nsns.despine(trim=True, left=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finding 2","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 3. Data preprocessing","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\n\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.linear_model import SGDRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.svm import SVR\nimport xgboost as xgb\n\nmodel_list = [(ElasticNet(),'ElasticNet'),\n              (SGDRegressor(),'SGDRegressor'),\n              (SVR(kernel='linear'),'SVR-linear'),\n              (SVR(kernel='rbf'),'SVR-rbf'),\n              (RandomForestRegressor(),'RandomForestRegressor'),\n              (xgb.XGBRegressor(),'XGBoost')\n             ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.copy().drop(columns='price')\ny = df['price'].copy()\nX_train,X_test,y_train,y_test = train_test_split(X,y,random_state=1, test_size = 0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_col = ['model', 'transmission', 'fuelType']\nnum_col = ['mileage', 'tax', 'mpg', 'age','engineSize']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# num_pipeline = Pipeline([\n#     ('std_scaler', StandardScaler())\n# ])\n# cat_pipeline = Pipeline([\n#     ('onehot_enc', OneHotEncoder())\n# ])\nfull_pipeline = ColumnTransformer([\n    ('num', StandardScaler(), num_col),\n    ('cat', OneHotEncoder(handle_unknown='ignore'), cat_col)\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_prepared = full_pipeline.fit_transform(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_score = []\n\nfor m in model_list:\n    model = m[0]\n#     model.fit(X_train_prepared,y_train)\n    score = cross_val_score(model,X_train_prepared,y_train,cv=4, scoring='r2')\n    print(f'{m[1]} score = {score.mean()}')\n    model_score.append([m[1],score.mean()])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"from cross validation score, we decide to continue develop on XGBoost model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}